---
layout: post
title: 쿠버네티스 개념
categories: ['kubernetes']
category: 'Kubernetes'
origins: ['https://www.udemy.com/course/docker-kubernetes-2022/']
published: true
---

# 쿠버네티스란?

자동 배포, 스케일링, 로드 밸렁싱 등 배포와 컨테이너 관리를 수행하는데 도움이 되는 도구이다.

배포하는 방식, 컨테이너 스케일링, 컨테이너가 실패할 경우의 모니터링 하는 방법과 컨테이너를 교체하는 방법을 정의할 수 있다.

이건 AWS 에서도 지원하는 기능이다. <br>
하지만 이를 진행하려면 모든 과정을 AWS 서비스로만 진행해야한다.

만약 AWS 가 아니라 Microsoft Auzure 와 같이 다른 클라우드 플랫폼으로 전환하고자한다면 그 과정을 모두 새로이해야한다.

이런 문제를 해결할 수 있는 것이 바로 쿠버네티스이다.

쿠버네티스로 배포 설정을 표준화하고, 플랫폼에 상관 없이 유연하게 컨테이너 관리와 배포 자동화를 유지시킬 수 있다.

즉, 쿠버네티스는 클라우드 플랫폼 뿐만아니라 내 개인 PC 에서도 사용할 수 있다.

쿠버네티스는 배포/관리 설정이 표준화 되어 있기 때문에 여러 머신에서 동일한 작업을 수행할 수 있다.<br>
쿠버네티스는 여러 머신을 위한 Dokcer-Compose 라고 생각할 수 있다.

# 쿠버네티스 구조 및 용어

![](/assets/images/k8s/k8s1.jpg)

## Pod

쿠버네티스에서 가장 작은 단위이다.<br>
하나 이상의 컨테이너를 포함하고 있고, 컨테이너를 실행시킨다.

## Worker Node

워커 노드는 하나 이상의 Pod 를 포함하고 있다.<br>
즉, Pod는 Worker Node 에서 실행된다.

Pod 가 실행되는 환경으로, 가상 인스턴스라고 생각하면 된다.<br>
AWS 의 EC2 같은 것이다.

여러 Pod 를 호스팅하고 관리하는 역할을 한다.

## Proxy

Worker Node 의 pod 네트워크 트래픽 제어를 설정하는 도구이다.<br>
Proxy 는 Pod 가 인터넷에 연결할 수 있는지의 여부와,
이런 Pod 및 그 내부에서 실행되는 컨테이너를 외부 세계에서 어떻게 접근할 수 있는지를 제어한다.

예를 들어, <br>
웹 어플리케이션 컨테이너가 있는 Pod 에<br>
사용자의 외부 트래픽이 이 컨테이너에 도달할 수 있도록 프록시를 구성해야한다.

## Service

위 이미지엔 나타나 있지 않지만 프록시와 밀접한 관계가 있는 용어가 하나 있는데, 바로 **서비스**이다.<br>
서비스는 특정 포드 집합을 외부 세계로 노출하여 특정 IP 주소 또는 도메인으로 연결할 수 있도록 하는 용어이다. 

## Master Node & Control Plane

마스터 노드는 스케일링과 로드밸런싱을 수행한다.

마스터 노드는 컨테이너와 포드를 만들고, 시작하고, <br>
장애가 나거나 더 이상 필요하지 않은 경우,<br>
이를 교체하거나 종료한다.
또한, 마스터 노드는 트래픽을 워커 노드로 분배한다.

이것은 정확히는 마스터 노드가 호출하는 컨트롤 플레인에 의해 수행된다.
즉, 마스터 노드는 워커 노드를 제어하는 중앙 제어 사무소이다.

워커 노드 또는 포드는 서로 직접 상호작용하지 않고 컨트롤 플레인을 통해 상호작용한다.<br>

마스터 노드는 워커 노드와 다른 머신으로 취급되어<br>
워커 노드가 다운되어도 마스터 노드가 함께 다운되지 않는다.

## Cluster

이 모든 것을 아우르는 것을 클러스터라고 한다.
이 최종 상태, 즉, 이 클러스터는 클라우드 프로바이더에 복제되어 사용된다.


## kubectl

클러스터에 명령을 보내는 도구이다.<br>
kubectl 도구를 사용하면 개발자 또는 관리자가 마스터 노드에 명령을 보낼 수 있다.

예를 들어, 개발자가 주어진 컨테이너의 더 많은 포드를 생성하라는 명령을 보내면, <br>마스터 노드와 워커 노드가 명령에 따라 상호작용하며 추가 포드를 생성한다. 

# 구체적인 Worker Node 의 구조

![](/assets/images/k8s/k8s2.jpg)

## Pod

앞서 워커 노드는 Pod 를 포함한다고 설명했다.<br>
그리고 Pod 내엔 컨테이너가 있다.

일반적으로 하나의 포드에 하나의 컨테이너가 있지만<br>
밀접하게 작동해야하는 여러 컨테이너가 있는 경우에는, <br>
포드 내부에 여러 컨테이너를 가질 수도 있다.

그리고 포드는 볼륨을 포함할 수 있다.<br>
컨테이너가 사용하는 리소스를 저장하는 하드 드라이브 일부 공간이다.<br>

포드는 워커 노드 내에 하나 이상 존재할 수 있다.<br>
각 포드는 완전히 다를수도 있고, 완전히 같은 복사본일 수도 있다.

예를 들어, 트래픽 분산을 위해 스케일링 한 경우엔 복사본 포드가 존재할 수 있다.

## Docker

워커 노드는 가상 인스턴스, 즉 호스팅 머신과 같다.<br>
그리고 워커 노드 내에서 컨테이너가 실행되어야하기 때문에,<br>
일반적인 머신처럼 Docker 의 설치가 필요하다.<br>
`docker run` 따위가 수행되어야하듯이 말이다.

## kubelet

워커 노드는 마스터 노드에 의해 제어되기 때문에,<br>
마스터 노드와 통신하기 위한 **kubelet** 이라는 소프트웨어가 필요하다.

## kube-proxy

워커 노드는 컨테이너로 들어오고 나가는 네트워크 트래픽을 제어하기 위해 Proxy가 필요하다.
일반적으로 **kube-proxy** 라고 한다.

# 구체적인 Master Node 의 구조

![](/assets/images/k8s/k8s3.jpg)

## API Server

kubelet 서비스에 대한 카운터 포인트 서버이다. <br>
(쉽게 말해 명령을 내리는 대장 서버)

## Scheduler

스케줄러는 포드를 관찰하고 새 포드가 생성되어야하는 워커 노드를 선택하는 일을 한다.
포드가 비정상적이거나, 다운되었거나, 또는 스케일링으로 인해 <br>
새 포드를 생성해야하는 경우이다.

즉, 이것이 실제로 워커 노드에 무엇을 명령할지 API 서버에 알리는 역할을 한다.

## kube-controller-manager

워커 노드 전체를 감시하고 제어하며 포드의 수가 적당한지 확인한다. <br>
즉, 스케줄러와 API 서버와 긴밀하게 연동된다.

## cloud-controller-manager

kube-controller-manager 와 동일한 역할을 하지만, <br>
어떤 클라우드 프로바이더(플랫폼) 을 쓰느냐에따라 다르다. <br>
클라우드 프로바이더에게 무엇을 해야하는지 알려준다.<br>
즉, 클라우드 컨트롤러 매니저는 AWS, Azure 등 어떤 클라우드 플랫폼이든지간에 명령을 번역해준다.
